{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('ds-venv': venv)"
  },
  "interpreter": {
   "hash": "6475bde1302f1cb475f3ccbdcef48982b2e5fbfc96cbdc40c6f55106b6e9d250"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Variable:\n",
    "    def __init__(self, value, local_gradients=[]):\n",
    "        self.value = value\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return add(self, other)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return mul(self, other)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return add(self, neg(other))\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        return mul(self, inv(other))\n",
    "    \n",
    "def add(a, b):\n",
    "    value = a.value + b.value    \n",
    "    local_gradients = (\n",
    "        (a, 1),\n",
    "        (b, 1)\n",
    "    )\n",
    "    return Variable(value, local_gradients)\n",
    "\n",
    "def mul(a, b):\n",
    "    value = a.value * b.value\n",
    "    local_gradients = (\n",
    "        (a, b.value),\n",
    "        (b, a.value)\n",
    "    )\n",
    "    return Variable(value, local_gradients)\n",
    "\n",
    "def neg(a):\n",
    "    value = -1 * a.value\n",
    "    local_gradients = (\n",
    "        (a, -1),\n",
    "    )\n",
    "    return Variable(value, local_gradients)\n",
    "\n",
    "def inv(a):\n",
    "    value = 1. / a.value\n",
    "    local_gradients = (\n",
    "        (a, -1 / a.value**2),\n",
    "    )\n",
    "    return Variable(value, local_gradients)\n",
    "\n",
    "\n",
    "def get_gradients(variable):\n",
    "    \"Compute the first partial derivatives of a variable wrt all the child variables.\"\n",
    "    gradients = defaultdict(int)\n",
    "\n",
    "    def compute_gradients(variable, path_value):\n",
    "        for child_variable, local_gradient in variable.local_gradients:\n",
    "            # Multiply all edges of a path\n",
    "            value_of_path_to_child = path_value * local_gradient\n",
    "            # Add together the different paths\n",
    "            gradients[child_variable] += value_of_path_to_child\n",
    "            # Recurse through the graph\n",
    "            compute_gradients(child_variable, value_of_path_to_child)\n",
    "\n",
    "    compute_gradients(variable, path_value=1)\n",
    "    # path_value=1 is from variable differentiated wrt itself\n",
    "    return gradients\n"
   ]
  },
  {
   "source": [
    "Example 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "a = Variable(4)\n",
    "b = Variable(3)\n",
    "c = a + b\n",
    "d = a * c\n",
    "gradients = get_gradients(d)\n",
    "\n",
    "print('d.value =', d.value)\n",
    "print(\"The partial derivative of d with respect to a =\", gradients[a])\n",
    "print(\"The partial derivative of d with respect to b =\", gradients[b])\n",
    "print(\"The partial derivative of d with respect to c =\", gradients[c])\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Example 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a, b):\n",
    "    return (a / b - a) * (b / a + a + b) * (a - b)\n",
    "\n",
    "a = Variable(230.3)\n",
    "b = Variable(33.2)\n",
    "y = f(a, b)\n",
    "\n",
    "gradients = get_gradients(y)\n",
    "\n",
    "print(\"The partial derivative of y with respect to a =\", gradients[a])\n",
    "print(\"The partial derivative of y with respect to b =\", gradients[b])\n"
   ]
  },
  {
   "source": [
    "A Simple Neural Net"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# convert NumPy array into array of Variable objects:\n",
    "to_var = np.vectorize(lambda x : Variable(x))\n",
    "\n",
    "# get values from array of Variable objects:\n",
    "to_vals = np.vectorize(lambda variable : variable.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 50\n",
    "output_size = 10\n",
    "lrate = 0.001\n",
    "x = to_var(np.random.random(input_size))\n",
    "y_true = to_var(np.random.random(output_size))\n",
    "weights = to_var(np.random.random((input_size, output_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "def update_weights(weights, gradients, lrate):\n",
    "    for _, weight in np.ndenumerate(weights):\n",
    "        weight.value -= lrate * gradients[weight]\n",
    "\n",
    "input_size = 50\n",
    "output_size = 10\n",
    "lrate = 0.001\n",
    "\n",
    "x = to_var(np.random.random(input_size))\n",
    "y_true = to_var(np.random.random(output_size))\n",
    "weights = to_var(np.random.random((input_size, output_size)))\n",
    "\n",
    "loss_vals = []\n",
    "for i in range(100):\n",
    "    y_pred = x @ weights\n",
    "    loss = np.sum((y_true - y_pred) * (y_true - y_pred))\n",
    "    loss_vals.append(loss.value)\n",
    "    gradients = get_gradients(loss)\n",
    "    update_weights(weights, gradients, lrate)\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Single linear layer learning\")\n",
    "plt.show()\n"
   ]
  }
 ]
}